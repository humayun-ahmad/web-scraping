# Web Scraping with Python

This repository is a collection of Python scripts and notebooks for web scraping various websites and extracting structured data. It includes multiple real-world scraping examples ranging from cricket match data, stock exchange information, and keyword searches, to scraping academy websites and handling HTML tag manipulations.

## üîç Project Highlights

* **Diverse Examples:** Includes scraping from sites like YouTube, Stack Overflow, Google Search, Dhaka Stock Exchange, and more.
* **Educational Focus:** Offers scripts for learning web scraping step-by-step with practical use cases.
* **Technologies Used:** Python, BeautifulSoup, Requests, Selenium, and Jupyter Notebooks.

## üìÅ Directory Overview

| Folder / File                            | Description                                    |
| ---------------------------------------- | ---------------------------------------------- |
| `Bank/`                                  | Long time data scraping for banks              |
| `Cricket/`                               | Extract point table of cricket matches         |
| `Data pulling/`                          | Script placeholder (under development)         |
| `Dhaka Stock Exchange/`                  | Data scraping from Dhaka Stock Exchange        |
| `Get and Post Request/`                  | Scripts for sending POST and GET HTTP requests |
| `Google Search and Get Website List/`    | Extract websites from Google Search results    |
| `Hand on with NBA project/`              | Image scraping project based on NBA            |
| `How to remove a tag from multiple tag/` | Tutorial to remove specific tags from HTML     |
| `KeyWord_search/`                        | Keyword search automation on websites          |
| `Live score from sofaScore/`             | Script to scrape live sports scores            |
| `Learncode.in/`                          | Scraping Learncode.in academy for content      |
| `Proxies and csv file/`                  | Using proxies and saving scraped data to CSV   |
| `Request-HTML/`                          | Example using `requests-html` library          |
| `Response of get_Request/`               | Handling response of HTTP GET requests         |
| `Selenium/`                              | Selenium automation examples                   |
| `Stack overflow/`                        | Scraping questions/answers from Stack Overflow |
| `Youtube_Subscription/`                  | YouTube subscription info scraping             |
| `Youtube_video_download/`                | YouTube video download logic                   |
| `bisssy site pulling/`                   | Web scraping of bisssy site                    |
| `coreyms_website_scraping/`              | CoreyMS blog scraping demo                     |
| `coronavirus data collect/`              | Coronavirus-related data collection            |
| `other files/`                           | Miscellaneous scripts                          |
| `string_optimization/`                   | Python script for string cleaning/optimization |
| `title_hunting/`                         | Title search and filtering from websites       |
| `translations/`                          | Extracting text under translation tags         |
| `README.md`                              | This file                                      |

## üõ† Requirements

* Python 3.6+
* Libraries:

  * `requests`
  * `beautifulsoup4`
  * `selenium`
  * `pandas`
  * `jupyter`
  * (others as needed per script)

Use `pip install -r requirements.txt` to install dependencies (create this file based on scripts).

## üöÄ Getting Started

Clone this repo and start with the folder most relevant to your need:

```bash
git clone https://github.com/humayun-ahmad/web-scraping.git
cd web-scraping
jupyter notebook
```

## üìå Tags

`python` `web-scraping` `scrapy` `selenium` `beautifulsoup` `automation` `data-pull`

## üôã‚Äç‚ôÇÔ∏è Author

**Humayun Ahmad Rajib**
üîó [Stack Overflow Profile](https://stackoverflow.com/users/9501508/humayun-ahmad-rajib)

## üìú License

This repository is provided for educational purposes. No warranty is expressed or implied.

---
